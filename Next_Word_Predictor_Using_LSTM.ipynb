{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2pGtrIaVMoup"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"\"\" Chapter 1\n",
        "IN THIS CHAPTER\n",
        "Reviewing the history of AI\n",
        "Emphasizing the role of data in gen AI\n",
        "projects\n",
        " »Discussing the importance of gen AI to\n",
        "the enterprise\n",
        " »Using a cloud data platform to manage gen AI initiatives\n",
        "Introducing Gen AI and the Role of Data\n",
        " Traditional AI, often referred to as machine learning (ML), has primarily focused on analytic tasks like classification and prediction.\n",
        "Generative AI (gen AI) goes a step further with its ability to create new, original content. This creative\n",
        "breakthrough has the potential to transform nearly every industry, enhancing human creativity and pushing the boundaries of what machines can accomplish. This chapter puts gen AI in a historical context, defines key terms, and introduces the data foundation that organizations need to succeed with gen AI initiatives.\n",
        "The Historical Context of Gen AI\n",
        "Gen AI is a type of artificial intelligence that uses neural networks and deep learning algorithms to identify patterns within existing data as a basis for generating original content.\n",
        "By learning patterns from large volumes of data, gen AI algorithms synthesize knowledge to create original text, images, audio, video, and other forms of output. To understand the transformative nature\n",
        "of these unique technologies, it is helpful to place them in their historical context.\n",
        "AI has a rich history marked by decades of steady progress,  occasional setbacks, and periodic breakthroughs. Although certain foundational ideas in AI can be traced back to the early 20th century, classical (or traditional) AI, which focused on rule based systems, had its inception in the 1950s and came into\n",
        "prominence in the ensuing decades.\n",
        "ML, which involves training computer algorithms to learn patterns and make predictions based on data, emerged in the 1980s.\n",
        "At about this same time, neural networks gained popularity, inspired by the structure and functioning of the human brain.\n",
        "These software systems use interconnected nodes (neurons) to process information.\n",
        "During the first two decades of the 21st century, deep learning revolutionized the AI landscape with its capability to handle large amounts of data and execute complex tasks.\n",
        "As a type of neural network, deep learning employs multiple layers of interconnected neurons, allowing for more sophisticated learning and representation of data.\n",
        "This breakthrough led to significant advancements in computer vision, speech recognition, and natural language\n",
        "processing (NLP), launching the era of general-purpose AI bots such as Siri and Alexa. Convolutional neural networks (CNNs) proved themselves to be particularly successful at computer vision tasks, while recurrent neural networks (RNNs) excelled in sequential data processing, such as language modeling. These technologies laid the foundation for gen AI.\n",
        " Introducing LLMs and foundation models\n",
        " Large language models (LLMs) are advanced AI systems designed to understand the intricacies of human language and to generate intelligent, creative responses when queried.\n",
        "Successful LLMs are trained on enormous data sets typically measured in petabytes (a million gigabytes). Training data has often been sourced from books, articles, websites, and other text-based sources, mostly in\n",
        "the public domain. Using deep learning techniques, these models excel at understanding and generating text similar to human produced content. Today’s LLMs power many modern applications, including content creation tools, language translation apps, customer service chatbots, financial analysis sites, scientific\n",
        "research repositories, and advanced Internet search tools.\n",
        "Generative AI and LLMs For Dummies, Snowflake Special Edition\n",
        "In the field of AI, language models are powerful software systems\n",
        "designed to understand, generate, and manipulate human language. Some models handle images and other media along with text.\n",
        "These are often referred to as multimodal language models.\n",
        "Transforming the AI landscape\n",
        "AI systems with humanlike reasoning capabilities have been around since the 1950s, but only with the advent of LLMs have they gained widespread adoption. According to a recent Forbes\n",
        "article called “Transformers Revolutionized AI.\n",
        "What Will Replace Them?” a key breakthrough came in 2017 when the Google Brain team introduced the transformer architecture, a deep learning model that replaced traditional recurrent and convolutional structures\n",
        "with a new type of architecture that’s particularly effective at understanding and contextualizing language, as well as generating text, images, audio, and computer code.\n",
        "LLMs based on the transformer architecture have enabled new realms of AI capabilities. Perhaps the best-known example is  OpenAI’s ChatGPT, which stands for chatbot generative pre\n",
        "trained transformer.\n",
        "A CNN article, “Microsoft confirms it’s investing billions in the creator of ChatGPT,” shows support for the development of progressively larger LLMs, some of which may incorporate hundreds of billions of parameters to generate coherent and contextually relevant responses.\n",
        "Accelerating AI functions\n",
        "Another important factor in the evolution of AI is the advent of accelerated hardware systems known as graphics processing units (GPUs).\n",
        "Although central processing units (CPUs) are designed for general-purpose computing tasks, GPUs, initially developed for graphics rendering, are specialized processors that have proven to be adept at ML tasks due to their unique architecture.\n",
        "GPUs have a large number of cores that can process multiple tasks simultaneously. Transformers use GPUs to process multiple threads of information, leading to faster training of AI models that effectively handle not just text but also images, audio, and video content. This parallel processing capability is crucial for the computationally intensive calculations involved in ML, such as\n",
        "CHAPTER 1  Introducing Gen AI and the Role of Data matrix operations. GPUs can perform these computations much\n",
        "faster than CPUs, accelerating training and inference times and enhancing the overall performance of ML algorithms. Refer to  Cloud Data Science For Dummies (Wiley) by David Baum for additional information on these concepts.\n",
        "Gen AI builds on traditional AI concepts while vastly expanding applicability, scaling potential — and with web-scale processing demands. The Role of Data in AI Projects.\n",
        "As impressive as they are at language generation, reasoning, and translation, gen AI applications that have been built on public data can’t realize their full potential in the enterprise until they’re coupled with enterprise data stores. Most organizations store massive amounts of data, both on-premises and in the cloud. Many of these businesses have data science practices that leverage structured data for traditional analytics, such as forecasting. To maximize the value of gen AI, these companies need to open up to the vast world of unstructured and semi-structured data as well. According to a February 2021 report from MIT titled “Tapping the Power of Unstructured Data,” 80 to 90 percent of data is unstructured — locked away in text, audio, social media, and other sources.\n",
        "For enterprises that figure out how to use this data, it can provide a competitive advantage, especially in the era of gen AI.\n",
        "To amass a complete data set, consider not only your internal first-party data, but also second-party data from partners and suppliers, and third-party data from a service provider or data\n",
        "marketplace. See the nearby sidebar for more information.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7YpvKPTUOESk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([text])\n"
      ],
      "metadata": {
        "id": "y592yeH-SfJJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkPMdDDDPuyo",
        "outputId": "c914bedd-34c9-441e-bcb5-9e496ac251c2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'and': 3,\n",
              " 'ai': 4,\n",
              " 'to': 5,\n",
              " 'data': 6,\n",
              " 'in': 7,\n",
              " 'a': 8,\n",
              " 'gen': 9,\n",
              " 'as': 10,\n",
              " 'for': 11,\n",
              " 'language': 12,\n",
              " 'on': 13,\n",
              " 'with': 14,\n",
              " 'that': 15,\n",
              " 'these': 16,\n",
              " 'learning': 17,\n",
              " 'llms': 18,\n",
              " 'this': 19,\n",
              " 'text': 20,\n",
              " 'models': 21,\n",
              " 'are': 22,\n",
              " 'have': 23,\n",
              " 'tasks': 24,\n",
              " 'is': 25,\n",
              " 'systems': 26,\n",
              " 'at': 27,\n",
              " 'processing': 28,\n",
              " 'traditional': 29,\n",
              " 'ml': 30,\n",
              " 'content': 31,\n",
              " 'human': 32,\n",
              " 'can': 33,\n",
              " 'neural': 34,\n",
              " 'deep': 35,\n",
              " 'from': 36,\n",
              " 'gpus': 37,\n",
              " 'chapter': 38,\n",
              " 'role': 39,\n",
              " 'has': 40,\n",
              " 'networks': 41,\n",
              " 'algorithms': 42,\n",
              " 'by': 43,\n",
              " 'large': 44,\n",
              " 'images': 45,\n",
              " 'audio': 46,\n",
              " 'other': 47,\n",
              " 'which': 48,\n",
              " 'based': 49,\n",
              " 'training': 50,\n",
              " 'computer': 51,\n",
              " 'information': 52,\n",
              " 'such': 53,\n",
              " 'architecture': 54,\n",
              " 'enterprise': 55,\n",
              " 'cloud': 56,\n",
              " 'introducing': 57,\n",
              " 'often': 58,\n",
              " 'generative': 59,\n",
              " 'its': 60,\n",
              " 'new': 61,\n",
              " 'original': 62,\n",
              " 'breakthrough': 63,\n",
              " 'potential': 64,\n",
              " 'historical': 65,\n",
              " 'context': 66,\n",
              " 'foundation': 67,\n",
              " 'type': 68,\n",
              " 'patterns': 69,\n",
              " 'generating': 70,\n",
              " 'understand': 71,\n",
              " 'their': 72,\n",
              " 'decades': 73,\n",
              " 'be': 74,\n",
              " 'use': 75,\n",
              " 'process': 76,\n",
              " 'handle': 77,\n",
              " 'multiple': 78,\n",
              " 'designed': 79,\n",
              " 'generate': 80,\n",
              " 'been': 81,\n",
              " 'but': 82,\n",
              " '”': 83,\n",
              " 'transformer': 84,\n",
              " 'unstructured': 85,\n",
              " 'party': 86,\n",
              " '1': 87,\n",
              " 'history': 88,\n",
              " 'projects': 89,\n",
              " 'initiatives': 90,\n",
              " 'referred': 91,\n",
              " 'focused': 92,\n",
              " 'create': 93,\n",
              " 'creative': 94,\n",
              " 'enhancing': 95,\n",
              " 'what': 96,\n",
              " 'key': 97,\n",
              " 'organizations': 98,\n",
              " 'need': 99,\n",
              " 'video': 100,\n",
              " 'unique': 101,\n",
              " 'technologies': 102,\n",
              " 'it': 103,\n",
              " 'them': 104,\n",
              " 'although': 105,\n",
              " 'century': 106,\n",
              " 'or': 107,\n",
              " '1950s': 108,\n",
              " 'came': 109,\n",
              " 'gained': 110,\n",
              " 'brain': 111,\n",
              " 'software': 112,\n",
              " 'interconnected': 113,\n",
              " 'neurons': 114,\n",
              " 'first': 115,\n",
              " 'revolutionized': 116,\n",
              " 'landscape': 117,\n",
              " 'capability': 118,\n",
              " 'amounts': 119,\n",
              " 'more': 120,\n",
              " 'vision': 121,\n",
              " 'era': 122,\n",
              " 'general': 123,\n",
              " 'purpose': 124,\n",
              " 'convolutional': 125,\n",
              " 'particularly': 126,\n",
              " 'successful': 127,\n",
              " 'while': 128,\n",
              " 'recurrent': 129,\n",
              " 'advanced': 130,\n",
              " 'responses': 131,\n",
              " 'when': 132,\n",
              " 'trained': 133,\n",
              " 'sources': 134,\n",
              " 'public': 135,\n",
              " 'understanding': 136,\n",
              " 'power': 137,\n",
              " 'many': 138,\n",
              " 'applications': 139,\n",
              " 'tools': 140,\n",
              " 'translation': 141,\n",
              " 'service': 142,\n",
              " 'dummies': 143,\n",
              " 'some': 144,\n",
              " 'media': 145,\n",
              " 'reasoning': 146,\n",
              " 'capabilities': 147,\n",
              " 'only': 148,\n",
              " 'advent': 149,\n",
              " 'they': 150,\n",
              " 'according': 151,\n",
              " 'article': 152,\n",
              " 'well': 153,\n",
              " 'known': 154,\n",
              " 'chatgpt': 155,\n",
              " 'billions': 156,\n",
              " 'accelerating': 157,\n",
              " 'graphics': 158,\n",
              " 'units': 159,\n",
              " 'cpus': 160,\n",
              " 'faster': 161,\n",
              " 'not': 162,\n",
              " 'also': 163,\n",
              " 'science': 164,\n",
              " 'concepts': 165,\n",
              " '—': 166,\n",
              " 'structured': 167,\n",
              " 'reviewing': 168,\n",
              " 'emphasizing': 169,\n",
              " '»discussing': 170,\n",
              " 'importance': 171,\n",
              " '»using': 172,\n",
              " 'platform': 173,\n",
              " 'manage': 174,\n",
              " 'machine': 175,\n",
              " 'primarily': 176,\n",
              " 'analytic': 177,\n",
              " 'like': 178,\n",
              " 'classification': 179,\n",
              " 'prediction': 180,\n",
              " 'goes': 181,\n",
              " 'step': 182,\n",
              " 'further': 183,\n",
              " 'ability': 184,\n",
              " 'transform': 185,\n",
              " 'nearly': 186,\n",
              " 'every': 187,\n",
              " 'industry': 188,\n",
              " 'creativity': 189,\n",
              " 'pushing': 190,\n",
              " 'boundaries': 191,\n",
              " 'machines': 192,\n",
              " 'accomplish': 193,\n",
              " 'puts': 194,\n",
              " 'defines': 195,\n",
              " 'terms': 196,\n",
              " 'introduces': 197,\n",
              " 'succeed': 198,\n",
              " 'artificial': 199,\n",
              " 'intelligence': 200,\n",
              " 'uses': 201,\n",
              " 'identify': 202,\n",
              " 'within': 203,\n",
              " 'existing': 204,\n",
              " 'basis': 205,\n",
              " 'volumes': 206,\n",
              " 'synthesize': 207,\n",
              " 'knowledge': 208,\n",
              " 'forms': 209,\n",
              " 'output': 210,\n",
              " 'transformative': 211,\n",
              " 'nature': 212,\n",
              " 'helpful': 213,\n",
              " 'place': 214,\n",
              " 'rich': 215,\n",
              " 'marked': 216,\n",
              " 'steady': 217,\n",
              " 'progress': 218,\n",
              " 'occasional': 219,\n",
              " 'setbacks': 220,\n",
              " 'periodic': 221,\n",
              " 'breakthroughs': 222,\n",
              " 'certain': 223,\n",
              " 'foundational': 224,\n",
              " 'ideas': 225,\n",
              " 'traced': 226,\n",
              " 'back': 227,\n",
              " 'early': 228,\n",
              " '20th': 229,\n",
              " 'classical': 230,\n",
              " 'rule': 231,\n",
              " 'had': 232,\n",
              " 'inception': 233,\n",
              " 'into': 234,\n",
              " 'prominence': 235,\n",
              " 'ensuing': 236,\n",
              " 'involves': 237,\n",
              " 'learn': 238,\n",
              " 'make': 239,\n",
              " 'predictions': 240,\n",
              " 'emerged': 241,\n",
              " '1980s': 242,\n",
              " 'about': 243,\n",
              " 'same': 244,\n",
              " 'time': 245,\n",
              " 'popularity': 246,\n",
              " 'inspired': 247,\n",
              " 'structure': 248,\n",
              " 'functioning': 249,\n",
              " 'nodes': 250,\n",
              " 'during': 251,\n",
              " 'two': 252,\n",
              " '21st': 253,\n",
              " 'execute': 254,\n",
              " 'complex': 255,\n",
              " 'network': 256,\n",
              " 'employs': 257,\n",
              " 'layers': 258,\n",
              " 'allowing': 259,\n",
              " 'sophisticated': 260,\n",
              " 'representation': 261,\n",
              " 'led': 262,\n",
              " 'significant': 263,\n",
              " 'advancements': 264,\n",
              " 'speech': 265,\n",
              " 'recognition': 266,\n",
              " 'natural': 267,\n",
              " 'nlp': 268,\n",
              " 'launching': 269,\n",
              " 'bots': 270,\n",
              " 'siri': 271,\n",
              " 'alexa': 272,\n",
              " 'cnns': 273,\n",
              " 'proved': 274,\n",
              " 'themselves': 275,\n",
              " 'rnns': 276,\n",
              " 'excelled': 277,\n",
              " 'sequential': 278,\n",
              " 'modeling': 279,\n",
              " 'laid': 280,\n",
              " 'intricacies': 281,\n",
              " 'intelligent': 282,\n",
              " 'queried': 283,\n",
              " 'enormous': 284,\n",
              " 'sets': 285,\n",
              " 'typically': 286,\n",
              " 'measured': 287,\n",
              " 'petabytes': 288,\n",
              " 'million': 289,\n",
              " 'gigabytes': 290,\n",
              " 'sourced': 291,\n",
              " 'books': 292,\n",
              " 'articles': 293,\n",
              " 'websites': 294,\n",
              " 'mostly': 295,\n",
              " 'domain': 296,\n",
              " 'using': 297,\n",
              " 'techniques': 298,\n",
              " 'excel': 299,\n",
              " 'similar': 300,\n",
              " 'produced': 301,\n",
              " 'today’s': 302,\n",
              " 'modern': 303,\n",
              " 'including': 304,\n",
              " 'creation': 305,\n",
              " 'apps': 306,\n",
              " 'customer': 307,\n",
              " 'chatbots': 308,\n",
              " 'financial': 309,\n",
              " 'analysis': 310,\n",
              " 'sites': 311,\n",
              " 'scientific': 312,\n",
              " 'research': 313,\n",
              " 'repositories': 314,\n",
              " 'internet': 315,\n",
              " 'search': 316,\n",
              " 'snowflake': 317,\n",
              " 'special': 318,\n",
              " 'edition': 319,\n",
              " 'field': 320,\n",
              " 'powerful': 321,\n",
              " 'manipulate': 322,\n",
              " 'along': 323,\n",
              " 'multimodal': 324,\n",
              " 'transforming': 325,\n",
              " 'humanlike': 326,\n",
              " 'around': 327,\n",
              " 'since': 328,\n",
              " 'widespread': 329,\n",
              " 'adoption': 330,\n",
              " 'recent': 331,\n",
              " 'forbes': 332,\n",
              " 'called': 333,\n",
              " '“transformers': 334,\n",
              " 'will': 335,\n",
              " 'replace': 336,\n",
              " '2017': 337,\n",
              " 'google': 338,\n",
              " 'team': 339,\n",
              " 'introduced': 340,\n",
              " 'model': 341,\n",
              " 'replaced': 342,\n",
              " 'structures': 343,\n",
              " 'that’s': 344,\n",
              " 'effective': 345,\n",
              " 'contextualizing': 346,\n",
              " 'code': 347,\n",
              " 'enabled': 348,\n",
              " 'realms': 349,\n",
              " 'perhaps': 350,\n",
              " 'best': 351,\n",
              " 'example': 352,\n",
              " 'openai’s': 353,\n",
              " 'stands': 354,\n",
              " 'chatbot': 355,\n",
              " 'pre': 356,\n",
              " 'cnn': 357,\n",
              " '“microsoft': 358,\n",
              " 'confirms': 359,\n",
              " 'it’s': 360,\n",
              " 'investing': 361,\n",
              " 'creator': 362,\n",
              " 'shows': 363,\n",
              " 'support': 364,\n",
              " 'development': 365,\n",
              " 'progressively': 366,\n",
              " 'larger': 367,\n",
              " 'may': 368,\n",
              " 'incorporate': 369,\n",
              " 'hundreds': 370,\n",
              " 'parameters': 371,\n",
              " 'coherent': 372,\n",
              " 'contextually': 373,\n",
              " 'relevant': 374,\n",
              " 'functions': 375,\n",
              " 'another': 376,\n",
              " 'important': 377,\n",
              " 'factor': 378,\n",
              " 'evolution': 379,\n",
              " 'accelerated': 380,\n",
              " 'hardware': 381,\n",
              " 'central': 382,\n",
              " 'computing': 383,\n",
              " 'initially': 384,\n",
              " 'developed': 385,\n",
              " 'rendering': 386,\n",
              " 'specialized': 387,\n",
              " 'processors': 388,\n",
              " 'proven': 389,\n",
              " 'adept': 390,\n",
              " 'due': 391,\n",
              " 'number': 392,\n",
              " 'cores': 393,\n",
              " 'simultaneously': 394,\n",
              " 'transformers': 395,\n",
              " 'threads': 396,\n",
              " 'leading': 397,\n",
              " 'effectively': 398,\n",
              " 'just': 399,\n",
              " 'parallel': 400,\n",
              " 'crucial': 401,\n",
              " 'computationally': 402,\n",
              " 'intensive': 403,\n",
              " 'calculations': 404,\n",
              " 'involved': 405,\n",
              " 'matrix': 406,\n",
              " 'operations': 407,\n",
              " 'perform': 408,\n",
              " 'computations': 409,\n",
              " 'much': 410,\n",
              " 'than': 411,\n",
              " 'inference': 412,\n",
              " 'times': 413,\n",
              " 'overall': 414,\n",
              " 'performance': 415,\n",
              " 'refer': 416,\n",
              " 'wiley': 417,\n",
              " 'david': 418,\n",
              " 'baum': 419,\n",
              " 'additional': 420,\n",
              " 'builds': 421,\n",
              " 'vastly': 422,\n",
              " 'expanding': 423,\n",
              " 'applicability': 424,\n",
              " 'scaling': 425,\n",
              " 'web': 426,\n",
              " 'scale': 427,\n",
              " 'demands': 428,\n",
              " 'impressive': 429,\n",
              " 'generation': 430,\n",
              " 'built': 431,\n",
              " 'can’t': 432,\n",
              " 'realize': 433,\n",
              " 'full': 434,\n",
              " 'until': 435,\n",
              " 'they’re': 436,\n",
              " 'coupled': 437,\n",
              " 'stores': 438,\n",
              " 'most': 439,\n",
              " 'store': 440,\n",
              " 'massive': 441,\n",
              " 'both': 442,\n",
              " 'premises': 443,\n",
              " 'businesses': 444,\n",
              " 'practices': 445,\n",
              " 'leverage': 446,\n",
              " 'analytics': 447,\n",
              " 'forecasting': 448,\n",
              " 'maximize': 449,\n",
              " 'value': 450,\n",
              " 'companies': 451,\n",
              " 'open': 452,\n",
              " 'up': 453,\n",
              " 'vast': 454,\n",
              " 'world': 455,\n",
              " 'semi': 456,\n",
              " 'february': 457,\n",
              " '2021': 458,\n",
              " 'report': 459,\n",
              " 'mit': 460,\n",
              " 'titled': 461,\n",
              " '“tapping': 462,\n",
              " '80': 463,\n",
              " '90': 464,\n",
              " 'percent': 465,\n",
              " 'locked': 466,\n",
              " 'away': 467,\n",
              " 'social': 468,\n",
              " 'enterprises': 469,\n",
              " 'figure': 470,\n",
              " 'out': 471,\n",
              " 'how': 472,\n",
              " 'provide': 473,\n",
              " 'competitive': 474,\n",
              " 'advantage': 475,\n",
              " 'especially': 476,\n",
              " 'amass': 477,\n",
              " 'complete': 478,\n",
              " 'set': 479,\n",
              " 'consider': 480,\n",
              " 'your': 481,\n",
              " 'internal': 482,\n",
              " 'second': 483,\n",
              " 'partners': 484,\n",
              " 'suppliers': 485,\n",
              " 'third': 486,\n",
              " 'provider': 487,\n",
              " 'marketplace': 488,\n",
              " 'see': 489,\n",
              " 'nearby': 490,\n",
              " 'sidebar': 491}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFWnoGoRQbsW",
        "outputId": "b7ef8064-9473-42f6-86e6-fadd941f38a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "491"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence=[]\n",
        "\n",
        "for sentence in text.split('\\n'):\n",
        "    tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "    for i in range(1,len(tokenized_sentence)):\n",
        "       input_sequence.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "MrtUwpxOP03C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=max([len(x) for x in input_sequence])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zzjKehEQ5WA",
        "outputId": "c1a15e41-d567-4a01-e151-a093a03b2051"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_sentences=pad_sequences(input_sequence, maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "CIAnpcDFRdjI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKIPtZR6R6VB",
        "outputId": "b77f6d17-9c94-46c8-ec19-1b0cd910beea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  38,  87],\n",
              "       [  0,   0,   0, ...,   0,   7,  19],\n",
              "       [  0,   0,   0, ...,   7,  19,  38],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 490, 491,  11],\n",
              "       [  0,   0,   0, ..., 491,  11, 120],\n",
              "       [  0,   0,   0, ...,  11, 120,  52]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=padded_sentences[:,:-1]\n",
        "y=padded_sentences[:,-1]"
      ],
      "metadata": {
        "id": "L2j4MjOTR8gF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=len(tokenizer.word_index)+1)"
      ],
      "metadata": {
        "id": "NfFYo3AxSGEY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM,Dense\n"
      ],
      "metadata": {
        "id": "AfA50cn_SbwB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Embedding(len(tokenizer.word_index)+1,100,input_length=max_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(len(tokenizer.word_index)+1,activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "wZLCFc9iStRQ",
        "outputId": "ce3a9407-48f2-4ed0-91c9-f0e6865e8f2a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia05bwOzUCmm",
        "outputId": "7b7df444-076e-4600-c86b-53a3f69f322d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 195ms/step - accuracy: 0.0266 - loss: 6.1168\n",
            "Epoch 2/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 259ms/step - accuracy: 0.0305 - loss: 5.6347\n",
            "Epoch 3/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.0419 - loss: 5.5814\n",
            "Epoch 4/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.0406 - loss: 5.5543\n",
            "Epoch 5/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - accuracy: 0.0467 - loss: 5.4621\n",
            "Epoch 6/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - accuracy: 0.0674 - loss: 5.3741\n",
            "Epoch 7/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 244ms/step - accuracy: 0.1017 - loss: 5.2503\n",
            "Epoch 8/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.0761 - loss: 5.1008\n",
            "Epoch 9/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - accuracy: 0.1390 - loss: 4.8568\n",
            "Epoch 10/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 197ms/step - accuracy: 0.1369 - loss: 4.6835\n",
            "Epoch 11/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 240ms/step - accuracy: 0.1654 - loss: 4.3943\n",
            "Epoch 12/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 251ms/step - accuracy: 0.1650 - loss: 4.2559\n",
            "Epoch 13/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.1764 - loss: 4.0751\n",
            "Epoch 14/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 246ms/step - accuracy: 0.2339 - loss: 3.8089\n",
            "Epoch 15/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 253ms/step - accuracy: 0.2330 - loss: 3.6236\n",
            "Epoch 16/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 232ms/step - accuracy: 0.2609 - loss: 3.4641\n",
            "Epoch 17/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 265ms/step - accuracy: 0.3290 - loss: 3.2045\n",
            "Epoch 18/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 271ms/step - accuracy: 0.3792 - loss: 3.0521\n",
            "Epoch 19/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 199ms/step - accuracy: 0.4229 - loss: 2.8376\n",
            "Epoch 20/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 189ms/step - accuracy: 0.4740 - loss: 2.6576\n",
            "Epoch 21/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 202ms/step - accuracy: 0.5448 - loss: 2.4390\n",
            "Epoch 22/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 248ms/step - accuracy: 0.5736 - loss: 2.3429\n",
            "Epoch 23/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 260ms/step - accuracy: 0.6146 - loss: 2.1655\n",
            "Epoch 24/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.6781 - loss: 1.9924\n",
            "Epoch 25/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 267ms/step - accuracy: 0.6916 - loss: 1.8804\n",
            "Epoch 26/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 209ms/step - accuracy: 0.7569 - loss: 1.7599\n",
            "Epoch 27/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - accuracy: 0.7801 - loss: 1.6077\n",
            "Epoch 28/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 253ms/step - accuracy: 0.8257 - loss: 1.4782\n",
            "Epoch 29/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 224ms/step - accuracy: 0.8583 - loss: 1.4014\n",
            "Epoch 30/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 211ms/step - accuracy: 0.8651 - loss: 1.2851\n",
            "Epoch 31/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 253ms/step - accuracy: 0.8822 - loss: 1.1824\n",
            "Epoch 32/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 200ms/step - accuracy: 0.9063 - loss: 1.0714\n",
            "Epoch 33/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 274ms/step - accuracy: 0.9130 - loss: 0.9841\n",
            "Epoch 34/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 219ms/step - accuracy: 0.9176 - loss: 0.9300\n",
            "Epoch 35/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 237ms/step - accuracy: 0.9368 - loss: 0.8350\n",
            "Epoch 36/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 248ms/step - accuracy: 0.9483 - loss: 0.7671\n",
            "Epoch 37/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 195ms/step - accuracy: 0.9508 - loss: 0.7439\n",
            "Epoch 38/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 192ms/step - accuracy: 0.9465 - loss: 0.7114\n",
            "Epoch 39/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 228ms/step - accuracy: 0.9588 - loss: 0.6106\n",
            "Epoch 40/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 256ms/step - accuracy: 0.9608 - loss: 0.5921\n",
            "Epoch 41/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 193ms/step - accuracy: 0.9576 - loss: 0.5563\n",
            "Epoch 42/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 250ms/step - accuracy: 0.9622 - loss: 0.5018\n",
            "Epoch 43/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 271ms/step - accuracy: 0.9682 - loss: 0.4611\n",
            "Epoch 44/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 245ms/step - accuracy: 0.9621 - loss: 0.4666\n",
            "Epoch 45/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 205ms/step - accuracy: 0.9729 - loss: 0.3923\n",
            "Epoch 46/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 238ms/step - accuracy: 0.9729 - loss: 0.4015\n",
            "Epoch 47/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 270ms/step - accuracy: 0.9737 - loss: 0.3624\n",
            "Epoch 48/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.9785 - loss: 0.3289\n",
            "Epoch 49/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 236ms/step - accuracy: 0.9820 - loss: 0.3279\n",
            "Epoch 50/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 212ms/step - accuracy: 0.9801 - loss: 0.3006\n",
            "Epoch 51/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 259ms/step - accuracy: 0.9836 - loss: 0.2895\n",
            "Epoch 52/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 340ms/step - accuracy: 0.9856 - loss: 0.2671\n",
            "Epoch 53/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 198ms/step - accuracy: 0.9846 - loss: 0.2578\n",
            "Epoch 54/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 296ms/step - accuracy: 0.9871 - loss: 0.2391\n",
            "Epoch 55/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 244ms/step - accuracy: 0.9866 - loss: 0.2195\n",
            "Epoch 56/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 212ms/step - accuracy: 0.9936 - loss: 0.2060\n",
            "Epoch 57/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - accuracy: 0.9849 - loss: 0.2243\n",
            "Epoch 58/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 194ms/step - accuracy: 0.9873 - loss: 0.1978\n",
            "Epoch 59/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 286ms/step - accuracy: 0.9936 - loss: 0.1822\n",
            "Epoch 60/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 294ms/step - accuracy: 0.9937 - loss: 0.1675\n",
            "Epoch 61/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 229ms/step - accuracy: 0.9895 - loss: 0.1697\n",
            "Epoch 62/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 235ms/step - accuracy: 0.9884 - loss: 0.1689\n",
            "Epoch 63/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 273ms/step - accuracy: 0.9892 - loss: 0.1585\n",
            "Epoch 64/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 302ms/step - accuracy: 0.9860 - loss: 0.1477\n",
            "Epoch 65/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - accuracy: 0.9911 - loss: 0.1501\n",
            "Epoch 66/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 258ms/step - accuracy: 0.9895 - loss: 0.1319\n",
            "Epoch 67/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 290ms/step - accuracy: 0.9876 - loss: 0.1285\n",
            "Epoch 68/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 252ms/step - accuracy: 0.9909 - loss: 0.1194\n",
            "Epoch 69/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 189ms/step - accuracy: 0.9888 - loss: 0.1235\n",
            "Epoch 70/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 241ms/step - accuracy: 0.9857 - loss: 0.1162\n",
            "Epoch 71/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 254ms/step - accuracy: 0.9914 - loss: 0.1079\n",
            "Epoch 72/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 189ms/step - accuracy: 0.9927 - loss: 0.1072\n",
            "Epoch 73/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 191ms/step - accuracy: 0.9924 - loss: 0.1056\n",
            "Epoch 74/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 237ms/step - accuracy: 0.9926 - loss: 0.0964\n",
            "Epoch 75/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 247ms/step - accuracy: 0.9877 - loss: 0.0986\n",
            "Epoch 76/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 192ms/step - accuracy: 0.9852 - loss: 0.1021\n",
            "Epoch 77/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 223ms/step - accuracy: 0.9919 - loss: 0.0855\n",
            "Epoch 78/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 221ms/step - accuracy: 0.9874 - loss: 0.0923\n",
            "Epoch 79/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 230ms/step - accuracy: 0.9946 - loss: 0.0787\n",
            "Epoch 80/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 245ms/step - accuracy: 0.9908 - loss: 0.0773\n",
            "Epoch 81/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 214ms/step - accuracy: 0.9902 - loss: 0.0763\n",
            "Epoch 82/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - accuracy: 0.9933 - loss: 0.0742\n",
            "Epoch 83/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 260ms/step - accuracy: 0.9936 - loss: 0.0697\n",
            "Epoch 84/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 252ms/step - accuracy: 0.9868 - loss: 0.0767\n",
            "Epoch 85/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 269ms/step - accuracy: 0.9888 - loss: 0.0637\n",
            "Epoch 86/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 207ms/step - accuracy: 0.9901 - loss: 0.0660\n",
            "Epoch 87/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 243ms/step - accuracy: 0.9921 - loss: 0.0599\n",
            "Epoch 88/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 253ms/step - accuracy: 0.9888 - loss: 0.0649\n",
            "Epoch 89/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - accuracy: 0.9871 - loss: 0.0693\n",
            "Epoch 90/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 196ms/step - accuracy: 0.9898 - loss: 0.0594\n",
            "Epoch 91/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - accuracy: 0.9892 - loss: 0.0624\n",
            "Epoch 92/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 197ms/step - accuracy: 0.9919 - loss: 0.0528\n",
            "Epoch 93/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 200ms/step - accuracy: 0.9935 - loss: 0.0540\n",
            "Epoch 94/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 253ms/step - accuracy: 0.9938 - loss: 0.0517\n",
            "Epoch 95/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 261ms/step - accuracy: 0.9866 - loss: 0.0586\n",
            "Epoch 96/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 194ms/step - accuracy: 0.9954 - loss: 0.0435\n",
            "Epoch 97/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 193ms/step - accuracy: 0.9922 - loss: 0.0479\n",
            "Epoch 98/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 253ms/step - accuracy: 0.9887 - loss: 0.0533\n",
            "Epoch 99/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.9924 - loss: 0.0450\n",
            "Epoch 100/100\n",
            "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 195ms/step - accuracy: 0.9912 - loss: 0.0447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79b9ab7799c0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=\"Let me tell you about Large Language Models\"\n",
        "for i in range(20):\n",
        "      tokenized_sentence=tokenizer.texts_to_sequences([input_text])[0]\n",
        "      padded_sentence=pad_sequences([tokenized_sentence],maxlen=128,padding='pre')\n",
        "      pos=np.argmax(model.predict(padded_sentence))\n",
        "      for word,index in tokenizer.word_index.items():\n",
        "        if index==pos:\n",
        "           input_text=input_text+\" \"+word\n",
        "           print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leGxp1sOWGpr",
        "outputId": "4488ac95-b340-4b4c-f8a5-0d22ae561fff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Let me tell you about Large Language Models llms\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Let me tell you about Large Language Models llms are\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Let me tell you about Large Language Models llms are advanced\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and to\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and to generate\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and to generate intelligent\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and to generate intelligent creative\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and to generate intelligent creative responses\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Let me tell you about Large Language Models llms are advanced ai systems designed to understand the intricacies of human language and to generate intelligent creative responses when\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0duMPeN2Uwea"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}